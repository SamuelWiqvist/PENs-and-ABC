Fri Nov  9 11:12:42 2018       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 396.44                 Driver Version: 396.44                    |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|===============================+======================+======================|
|   0  Tesla K80           On   | 00000000:04:00.0 Off |                    0 |
| N/A   41C    P0    75W / 149W |   9244MiB / 11441MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
|   1  Tesla K80           On   | 00000000:05:00.0 Off |                    0 |
| N/A   62C    P0    89W / 149W |    434MiB / 11441MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
|   2  Tesla K80           On   | 00000000:84:00.0 Off |                    0 |
| N/A   24C    P8    26W / 149W |      0MiB / 11441MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
|   3  Tesla K80           On   | 00000000:85:00.0 Off |                    0 |
| N/A   31C    P8    30W / 149W |      0MiB / 11441MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                       GPU Memory |
|  GPU       PID   Type   Process name                             Usage      |
|=============================================================================|
|    0    165146      C   julia                                       9231MiB |
|    1    165343      C   julia                                        423MiB |
+-----------------------------------------------------------------------------+
/home/samwiq/ABC and deep learning project/abc-dl/lunarc
/home/samwiq/ABC and deep learning project/abc-dl
start script
DNN_simple
standard
500
1
1
check version of Knet
    Status `~/.julia/environments/v1.0/Project.toml`
  [336ed68f] CSV v0.3.1
  [a93c6f00] DataFrames v0.13.1
  [31c24e10] Distributions v0.16.4
  [1902f260] Knet v1.1.0
  [6f286f6a] MultivariateStats v0.6.0 #master (https://github.com/JuliaStats/MultivariateStats.jl.git)
  [2913bbd2] StatsBase v0.25.0
  [4c63d2b9] StatsFuns v0.7.0
build Knet
  Building SpecialFunctions → `~/.julia/packages/SpecialFunctions/KvXoO/deps/build.log`
  Building CodecZlib ───────→ `~/.julia/packages/CodecZlib/wwgbh/deps/build.log`
  Building Knet ────────────→ `~/.julia/packages/Knet/hxjeS/deps/build.log`
test gpu
4
-1
0
Loading AR2 model
Starting: generate_parameter_data_pairs
Percentage done:  0.83 %
Percentage done:  1.65 %
Percentage done:  2.48 %
Percentage done:  3.31 %
Percentage done:  4.13 %
Percentage done:  4.96 %
Percentage done:  5.79 %
Percentage done:  6.61 %
Percentage done:  7.44 %
Percentage done:  8.26 %
Percentage done:  9.09 %
Percentage done:  9.92 %
Percentage done:  10.74 %
Percentage done:  11.57 %
Percentage done:  12.40 %
Percentage done:  13.22 %
Percentage done:  14.05 %
Percentage done:  14.88 %
Percentage done:  15.70 %
Percentage done:  16.53 %
Percentage done:  17.36 %
Percentage done:  18.18 %
Percentage done:  19.01 %
Percentage done:  19.83 %
Percentage done:  20.66 %
Percentage done:  21.49 %
Percentage done:  22.31 %
Percentage done:  23.14 %
Percentage done:  23.97 %
Percentage done:  24.79 %
Percentage done:  25.62 %
Percentage done:  26.45 %
Percentage done:  27.27 %
Percentage done:  28.10 %
Percentage done:  28.93 %
Percentage done:  29.75 %
Percentage done:  30.58 %
Percentage done:  31.40 %
Percentage done:  32.23 %
Percentage done:  33.06 %
Percentage done:  33.88 %
Percentage done:  34.71 %
Percentage done:  35.54 %
Percentage done:  36.36 %
Percentage done:  37.19 %
Percentage done:  38.02 %
Percentage done:  38.84 %
Percentage done:  39.67 %
Percentage done:  40.50 %
Percentage done:  41.32 %
Percentage done:  42.15 %
Percentage done:  42.98 %
Percentage done:  43.80 %
Percentage done:  44.63 %
Percentage done:  45.45 %
Percentage done:  46.28 %
Percentage done:  47.11 %
Percentage done:  47.93 %
Percentage done:  48.76 %
Percentage done:  49.59 %
Percentage done:  50.41 %
Percentage done:  51.24 %
Percentage done:  52.07 %
Percentage done:  52.89 %
Percentage done:  53.72 %
Percentage done:  54.55 %
Percentage done:  55.37 %
Percentage done:  56.20 %
Percentage done:  57.02 %
Percentage done:  57.85 %
Percentage done:  58.68 %
Percentage done:  59.50 %
Percentage done:  60.33 %
Percentage done:  61.16 %
Percentage done:  61.98 %
Percentage done:  62.81 %
Percentage done:  63.64 %
Percentage done:  64.46 %
Percentage done:  65.29 %
Percentage done:  66.12 %
Percentage done:  66.94 %
Percentage done:  67.77 %
Percentage done:  68.60 %
Percentage done:  69.42 %
Percentage done:  70.25 %
Percentage done:  71.07 %
Percentage done:  71.90 %
Percentage done:  72.73 %
Percentage done:  73.55 %
Percentage done:  74.38 %
Percentage done:  75.21 %
Percentage done:  76.03 %
Percentage done:  76.86 %
Percentage done:  77.69 %
Percentage done:  78.51 %
Percentage done:  79.34 %
Percentage done:  80.17 %
Percentage done:  80.99 %
Percentage done:  81.82 %
Percentage done:  82.64 %
Percentage done:  83.47 %
Percentage done:  84.30 %
Percentage done:  85.12 %
Percentage done:  85.95 %
Percentage done:  86.78 %
Percentage done:  87.60 %
Percentage done:  88.43 %
Percentage done:  89.26 %
Percentage done:  90.08 %
Percentage done:  90.91 %
Percentage done:  91.74 %
Percentage done:  92.56 %
Percentage done:  93.39 %
Percentage done:  94.21 %
Percentage done:  95.04 %
Percentage done:  95.87 %
Percentage done:  96.69 %
Percentage done:  97.52 %
Percentage done:  98.35 %
Percentage done:  99.17 %
Percentage done:  100.00 %
Nbr training obs 1000000, nbr parameters 25352, obs/parameters 39.44
0
Starting training
Epoch 1, current loss (training) 0.1829, current loss (val) 0.1831
Epoch 2, current loss (training) 0.0724, current loss (val) 0.0779
Epoch 3, current loss (training) 0.0402, current loss (val) 0.0418
Epoch 4, current loss (training) 0.0301, current loss (val) 0.0307
Epoch 5, current loss (training) 0.0264, current loss (val) 0.0278
Epoch 6, current loss (training) 0.0228, current loss (val) 0.0242
Epoch 7, current loss (training) 0.0223, current loss (val) 0.0232
Epoch 8, current loss (training) 0.0239, current loss (val) 0.0246
Epoch 9, current loss (training) 0.0207, current loss (val) 0.0220
Epoch 10, current loss (training) 0.0219, current loss (val) 0.0230
Epoch 11, current loss (training) 0.0224, current loss (val) 0.0226
Epoch 12, current loss (training) 0.0203, current loss (val) 0.0209
Epoch 13, current loss (training) 0.0208, current loss (val) 0.0219
Epoch 14, current loss (training) 0.0200, current loss (val) 0.0215
Epoch 15, current loss (training) 0.0204, current loss (val) 0.0213
Epoch 16, current loss (training) 0.0202, current loss (val) 0.0204
Epoch 17, current loss (training) 0.0207, current loss (val) 0.0210
Epoch 18, current loss (training) 0.0207, current loss (val) 0.0208
Epoch 19, current loss (training) 0.0190, current loss (val) 0.0202
Epoch 20, current loss (training) 0.0192, current loss (val) 0.0202
Epoch 21, current loss (training) 0.0188, current loss (val) 0.0202
Epoch 22, current loss (training) 0.0227, current loss (val) 0.0234
Epoch 23, current loss (training) 0.0208, current loss (val) 0.0205
Epoch 24, current loss (training) 0.0195, current loss (val) 0.0202
Epoch 25, current loss (training) 0.0191, current loss (val) 0.0201
Epoch 26, current loss (training) 0.0206, current loss (val) 0.0218
Epoch 27, current loss (training) 0.0193, current loss (val) 0.0203
Epoch 28, current loss (training) 0.0194, current loss (val) 0.0203
Epoch 29, current loss (training) 0.0210, current loss (val) 0.0215
Epoch 30, current loss (training) 0.0182, current loss (val) 0.0199
Epoch 31, current loss (training) 0.0195, current loss (val) 0.0198
Epoch 32, current loss (training) 0.0188, current loss (val) 0.0195
Epoch 33, current loss (training) 0.0192, current loss (val) 0.0200
Epoch 34, current loss (training) 0.0189, current loss (val) 0.0195
Epoch 35, current loss (training) 0.0190, current loss (val) 0.0202
Epoch 36, current loss (training) 0.0181, current loss (val) 0.0195
Epoch 37, current loss (training) 0.0183, current loss (val) 0.0193
Epoch 38, current loss (training) 0.0198, current loss (val) 0.0201
Epoch 39, current loss (training) 0.0183, current loss (val) 0.0194
Epoch 40, current loss (training) 0.0189, current loss (val) 0.0197
Epoch 41, current loss (training) 0.0194, current loss (val) 0.0197
Epoch 42, current loss (training) 0.0192, current loss (val) 0.0196
Epoch 43, current loss (training) 0.0196, current loss (val) 0.0206
Epoch 44, current loss (training) 0.0189, current loss (val) 0.0196
Epoch 45, current loss (training) 0.0204, current loss (val) 0.0222
Epoch 46, current loss (training) 0.0179, current loss (val) 0.0194
Epoch 47, current loss (training) 0.0187, current loss (val) 0.0195
Epoch 48, current loss (training) 0.0195, current loss (val) 0.0200
Epoch 49, current loss (training) 0.0201, current loss (val) 0.0205
Epoch 50, current loss (training) 0.0181, current loss (val) 0.0193
Epoch 51, current loss (training) 0.0192, current loss (val) 0.0200
Epoch 52, current loss (training) 0.0186, current loss (val) 0.0193
Epoch 53, current loss (training) 0.0184, current loss (val) 0.0192
Epoch 54, current loss (training) 0.0189, current loss (val) 0.0199
Epoch 55, current loss (training) 0.0183, current loss (val) 0.0196
Epoch 56, current loss (training) 0.0189, current loss (val) 0.0194
Epoch 57, current loss (training) 0.0184, current loss (val) 0.0200
Epoch 58, current loss (training) 0.0198, current loss (val) 0.0213
Epoch 59, current loss (training) 0.0196, current loss (val) 0.0197
Epoch 60, current loss (training) 0.0185, current loss (val) 0.0191
Epoch 61, current loss (training) 0.0195, current loss (val) 0.0198
Epoch 62, current loss (training) 0.0185, current loss (val) 0.0200
Epoch 63, current loss (training) 0.0182, current loss (val) 0.0190
Epoch 64, current loss (training) 0.0185, current loss (val) 0.0196
Epoch 65, current loss (training) 0.0185, current loss (val) 0.0196
Epoch 66, current loss (training) 0.0180, current loss (val) 0.0189
Epoch 67, current loss (training) 0.0185, current loss (val) 0.0189
Epoch 68, current loss (training) 0.0183, current loss (val) 0.0195
Epoch 69, current loss (training) 0.0206, current loss (val) 0.0218
Epoch 70, current loss (training) 0.0181, current loss (val) 0.0195
Epoch 71, current loss (training) 0.0188, current loss (val) 0.0201
Epoch 72, current loss (training) 0.0186, current loss (val) 0.0196
Epoch 73, current loss (training) 0.0205, current loss (val) 0.0209
Epoch 74, current loss (training) 0.0185, current loss (val) 0.0196
Epoch 75, current loss (training) 0.0184, current loss (val) 0.0191
Epoch 76, current loss (training) 0.0195, current loss (val) 0.0212
Epoch 77, current loss (training) 0.0180, current loss (val) 0.0195
Epoch 78, current loss (training) 0.0180, current loss (val) 0.0190
Epoch 79, current loss (training) 0.0179, current loss (val) 0.0188
Epoch 80, current loss (training) 0.0186, current loss (val) 0.0192
Epoch 81, current loss (training) 0.0185, current loss (val) 0.0197
Epoch 82, current loss (training) 0.0184, current loss (val) 0.0192
Epoch 83, current loss (training) 0.0182, current loss (val) 0.0196
Epoch 84, current loss (training) 0.0179, current loss (val) 0.0192
Epoch 85, current loss (training) 0.0196, current loss (val) 0.0200
Epoch 86, current loss (training) 0.0182, current loss (val) 0.0191
Epoch 87, current loss (training) 0.0180, current loss (val) 0.0196
Epoch 88, current loss (training) 0.0196, current loss (val) 0.0207
Epoch 89, current loss (training) 0.0180, current loss (val) 0.0192
Epoch 90, current loss (training) 0.0181, current loss (val) 0.0194
Epoch 91, current loss (training) 0.0188, current loss (val) 0.0204
Epoch 92, current loss (training) 0.0197, current loss (val) 0.0204
Epoch 93, current loss (training) 0.0186, current loss (val) 0.0190
Epoch 94, current loss (training) 0.0177, current loss (val) 0.0192
Epoch 95, current loss (training) 0.0173, current loss (val) 0.0191
Epoch 96, current loss (training) 0.0196, current loss (val) 0.0203
Epoch 97, current loss (training) 0.0188, current loss (val) 0.0193
Epoch 98, current loss (training) 0.0181, current loss (val) 0.0194
Epoch 99, current loss (training) 0.0188, current loss (val) 0.0195
Epoch 100, current loss (training) 0.0177, current loss (val) 0.0190
Epoch 101, current loss (training) 0.0176, current loss (val) 0.0192
Epoch 102, current loss (training) 0.0174, current loss (val) 0.0187
Epoch 103, current loss (training) 0.0185, current loss (val) 0.0197
Epoch 104, current loss (training) 0.0188, current loss (val) 0.0195
Epoch 105, current loss (training) 0.0179, current loss (val) 0.0191
Epoch 106, current loss (training) 0.0181, current loss (val) 0.0189
Epoch 107, current loss (training) 0.0181, current loss (val) 0.0194
Epoch 108, current loss (training) 0.0179, current loss (val) 0.0191
Epoch 109, current loss (training) 0.0181, current loss (val) 0.0192
Epoch 110, current loss (training) 0.0181, current loss (val) 0.0190
Epoch 111, current loss (training) 0.0184, current loss (val) 0.0195
Epoch 112, current loss (training) 0.0188, current loss (val) 0.0195
Epoch 113, current loss (training) 0.0189, current loss (val) 0.0193
Epoch 114, current loss (training) 0.0180, current loss (val) 0.0192
Epoch 115, current loss (training) 0.0181, current loss (val) 0.0193
Epoch 116, current loss (training) 0.0184, current loss (val) 0.0196
Epoch 117, current loss (training) 0.0178, current loss (val) 0.0189
Epoch 118, current loss (training) 0.0177, current loss (val) 0.0191
Epoch 119, current loss (training) 0.0178, current loss (val) 0.0194
Epoch 120, current loss (training) 0.0187, current loss (val) 0.0192
Epoch 121, current loss (training) 0.0181, current loss (val) 0.0192
Epoch 122, current loss (training) 0.0187, current loss (val) 0.0193
Epoch 123, current loss (training) 0.0183, current loss (val) 0.0196
Epoch 124, current loss (training) 0.0192, current loss (val) 0.0204
Epoch 125, current loss (training) 0.0172, current loss (val) 0.0188
Epoch 126, current loss (training) 0.0185, current loss (val) 0.0188
Epoch 127, current loss (training) 0.0182, current loss (val) 0.0193
Epoch 128, current loss (training) 0.0186, current loss (val) 0.0195
Epoch 129, current loss (training) 0.0176, current loss (val) 0.0190
Epoch 130, current loss (training) 0.0175, current loss (val) 0.0188
Epoch 131, current loss (training) 0.0191, current loss (val) 0.0203
Epoch 132, current loss (training) 0.0180, current loss (val) 0.0190
Epoch 133, current loss (training) 0.0188, current loss (val) 0.0191
Epoch 134, current loss (training) 0.0183, current loss (val) 0.0193
Epoch 135, current loss (training) 0.0180, current loss (val) 0.0191
Epoch 136, current loss (training) 0.0185, current loss (val) 0.0195
Epoch 137, current loss (training) 0.0178, current loss (val) 0.0196
Epoch 138, current loss (training) 0.0180, current loss (val) 0.0186
Epoch 139, current loss (training) 0.0185, current loss (val) 0.0191
Epoch 140, current loss (training) 0.0176, current loss (val) 0.0188
Epoch 141, current loss (training) 0.0181, current loss (val) 0.0188
Epoch 142, current loss (training) 0.0196, current loss (val) 0.0222
Epoch 143, current loss (training) 0.0189, current loss (val) 0.0205
Epoch 144, current loss (training) 0.0176, current loss (val) 0.0189
Epoch 145, current loss (training) 0.0199, current loss (val) 0.0208
Epoch 146, current loss (training) 0.0183, current loss (val) 0.0192
Epoch 147, current loss (training) 0.0182, current loss (val) 0.0191
Epoch 148, current loss (training) 0.0182, current loss (val) 0.0199
Epoch 149, current loss (training) 0.0182, current loss (val) 0.0191
Epoch 150, current loss (training) 0.0179, current loss (val) 0.0190
Epoch 151, current loss (training) 0.0174, current loss (val) 0.0190
Epoch 152, current loss (training) 0.0179, current loss (val) 0.0189
Epoch 153, current loss (training) 0.0173, current loss (val) 0.0189
Epoch 154, current loss (training) 0.0174, current loss (val) 0.0187
Epoch 155, current loss (training) 0.0184, current loss (val) 0.0199
Epoch 156, current loss (training) 0.0186, current loss (val) 0.0198
Epoch 157, current loss (training) 0.0183, current loss (val) 0.0203
Epoch 158, current loss (training) 0.0177, current loss (val) 0.0189
Epoch 159, current loss (training) 0.0180, current loss (val) 0.0190
Epoch 160, current loss (training) 0.0178, current loss (val) 0.0191
Epoch 161, current loss (training) 0.0186, current loss (val) 0.0193
Epoch 162, current loss (training) 0.0179, current loss (val) 0.0189
Epoch 163, current loss (training) 0.0176, current loss (val) 0.0191
Epoch 164, current loss (training) 0.0185, current loss (val) 0.0194
Epoch 165, current loss (training) 0.0182, current loss (val) 0.0193
Epoch 166, current loss (training) 0.0173, current loss (val) 0.0188
Epoch 167, current loss (training) 0.0182, current loss (val) 0.0192
Epoch 168, current loss (training) 0.0178, current loss (val) 0.0189
Epoch 169, current loss (training) 0.0179, current loss (val) 0.0188
Epoch 170, current loss (training) 0.0177, current loss (val) 0.0188
Epoch 171, current loss (training) 0.0180, current loss (val) 0.0191
Epoch 172, current loss (training) 0.0185, current loss (val) 0.0195
Epoch 173, current loss (training) 0.0184, current loss (val) 0.0196
Epoch 174, current loss (training) 0.0176, current loss (val) 0.0191
Epoch 175, current loss (training) 0.0175, current loss (val) 0.0188
Epoch 176, current loss (training) 0.0177, current loss (val) 0.0192
Epoch 177, current loss (training) 0.0180, current loss (val) 0.0190
Epoch 178, current loss (training) 0.0175, current loss (val) 0.0189
Epoch 179, current loss (training) 0.0177, current loss (val) 0.0188
Epoch 180, current loss (training) 0.0181, current loss (val) 0.0189
Epoch 181, current loss (training) 0.0188, current loss (val) 0.0194
Epoch 182, current loss (training) 0.0177, current loss (val) 0.0189
Epoch 183, current loss (training) 0.0186, current loss (val) 0.0203
Epoch 184, current loss (training) 0.0182, current loss (val) 0.0192
Epoch 185, current loss (training) 0.0199, current loss (val) 0.0204
Epoch 186, current loss (training) 0.0177, current loss (val) 0.0185
Epoch 187, current loss (training) 0.0185, current loss (val) 0.0190
Epoch 188, current loss (training) 0.0177, current loss (val) 0.0187
Epoch 189, current loss (training) 0.0182, current loss (val) 0.0192
Epoch 190, current loss (training) 0.0191, current loss (val) 0.0197
Epoch 191, current loss (training) 0.0176, current loss (val) 0.0193
Epoch 192, current loss (training) 0.0176, current loss (val) 0.0189
Epoch 193, current loss (training) 0.0177, current loss (val) 0.0187
Epoch 194, current loss (training) 0.0191, current loss (val) 0.0203
Epoch 195, current loss (training) 0.0179, current loss (val) 0.0186
Epoch 196, current loss (training) 0.0253, current loss (val) 0.0261
Epoch 197, current loss (training) 0.0178, current loss (val) 0.0190
Epoch 198, current loss (training) 0.0187, current loss (val) 0.0195
Epoch 199, current loss (training) 0.0178, current loss (val) 0.0189
Epoch 200, current loss (training) 0.0176, current loss (val) 0.0191
Epoch 201, current loss (training) 0.0181, current loss (val) 0.0190
Epoch 202, current loss (training) 0.0175, current loss (val) 0.0185
Epoch 203, current loss (training) 0.0178, current loss (val) 0.0190
Epoch 204, current loss (training) 0.0183, current loss (val) 0.0191
Epoch 205, current loss (training) 0.0210, current loss (val) 0.0221
Epoch 206, current loss (training) 0.0175, current loss (val) 0.0188
Epoch 207, current loss (training) 0.0178, current loss (val) 0.0188
Epoch 208, current loss (training) 0.0179, current loss (val) 0.0188
Epoch 209, current loss (training) 0.0180, current loss (val) 0.0194
Epoch 210, current loss (training) 0.0181, current loss (val) 0.0192
Epoch 211, current loss (training) 0.0183, current loss (val) 0.0191
Epoch 212, current loss (training) 0.0178, current loss (val) 0.0187
Epoch 213, current loss (training) 0.0183, current loss (val) 0.0190
Epoch 214, current loss (training) 0.0181, current loss (val) 0.0193
Epoch 215, current loss (training) 0.0179, current loss (val) 0.0191
Epoch 216, current loss (training) 0.0177, current loss (val) 0.0191
Epoch 217, current loss (training) 0.0171, current loss (val) 0.0189
Epoch 218, current loss (training) 0.0184, current loss (val) 0.0192
Epoch 219, current loss (training) 0.0185, current loss (val) 0.0197
Epoch 220, current loss (training) 0.0178, current loss (val) 0.0189
Epoch 221, current loss (training) 0.0178, current loss (val) 0.0197
Epoch 222, current loss (training) 0.0177, current loss (val) 0.0186
Epoch 223, current loss (training) 0.0174, current loss (val) 0.0188
Epoch 224, current loss (training) 0.0172, current loss (val) 0.0188
Epoch 225, current loss (training) 0.0184, current loss (val) 0.0192
Epoch 226, current loss (training) 0.0183, current loss (val) 0.0189
Epoch 227, current loss (training) 0.0173, current loss (val) 0.0187
Epoch 228, current loss (training) 0.0177, current loss (val) 0.0190
Epoch 229, current loss (training) 0.0204, current loss (val) 0.0213
Epoch 230, current loss (training) 0.0181, current loss (val) 0.0189
Epoch 231, current loss (training) 0.0175, current loss (val) 0.0190
Epoch 232, current loss (training) 0.0181, current loss (val) 0.0185
Epoch 233, current loss (training) 0.0184, current loss (val) 0.0191
Epoch 234, current loss (training) 0.0179, current loss (val) 0.0188
Epoch 235, current loss (training) 0.0175, current loss (val) 0.0186
Epoch 236, current loss (training) 0.0177, current loss (val) 0.0187
Epoch 237, current loss (training) 0.0175, current loss (val) 0.0189
Epoch 238, current loss (training) 0.0178, current loss (val) 0.0186
Epoch 239, current loss (training) 0.0178, current loss (val) 0.0189
Epoch 240, current loss (training) 0.0180, current loss (val) 0.0187
Epoch 241, current loss (training) 0.0183, current loss (val) 0.0193
Epoch 242, current loss (training) 0.0173, current loss (val) 0.0185
Epoch 243, current loss (training) 0.0181, current loss (val) 0.0188
Epoch 244, current loss (training) 0.0183, current loss (val) 0.0193
Epoch 245, current loss (training) 0.0177, current loss (val) 0.0189
Epoch 246, current loss (training) 0.0184, current loss (val) 0.0196
Epoch 247, current loss (training) 0.0183, current loss (val) 0.0189
Epoch 248, current loss (training) 0.0178, current loss (val) 0.0190
Epoch 249, current loss (training) 0.0184, current loss (val) 0.0192
Epoch 250, current loss (training) 0.0184, current loss (val) 0.0191
Epoch 251, current loss (training) 0.0177, current loss (val) 0.0188
Epoch 252, current loss (training) 0.0183, current loss (val) 0.0191
Epoch 253, current loss (training) 0.0176, current loss (val) 0.0190
Epoch 254, current loss (training) 0.0176, current loss (val) 0.0188
Epoch 255, current loss (training) 0.0177, current loss (val) 0.0188
Epoch 256, current loss (training) 0.0174, current loss (val) 0.0186
Epoch 257, current loss (training) 0.0176, current loss (val) 0.0187
Epoch 258, current loss (training) 0.0179, current loss (val) 0.0191
Epoch 259, current loss (training) 0.0179, current loss (val) 0.0188
Epoch 260, current loss (training) 0.0176, current loss (val) 0.0187
Epoch 261, current loss (training) 0.0184, current loss (val) 0.0194
Epoch 262, current loss (training) 0.0181, current loss (val) 0.0193
Epoch 263, current loss (training) 0.0176, current loss (val) 0.0201
Epoch 264, current loss (training) 0.0181, current loss (val) 0.0185
Epoch 265, current loss (training) 0.0179, current loss (val) 0.0188
Epoch 266, current loss (training) 0.0179, current loss (val) 0.0186
Epoch 267, current loss (training) 0.0175, current loss (val) 0.0187
Epoch 268, current loss (training) 0.0189, current loss (val) 0.0204
Epoch 269, current loss (training) 0.0181, current loss (val) 0.0196
Epoch 270, current loss (training) 0.0179, current loss (val) 0.0189
Epoch 271, current loss (training) 0.0171, current loss (val) 0.0187
Epoch 272, current loss (training) 0.0185, current loss (val) 0.0191
Epoch 273, current loss (training) 0.0178, current loss (val) 0.0188
Epoch 274, current loss (training) 0.0184, current loss (val) 0.0189
Epoch 275, current loss (training) 0.0172, current loss (val) 0.0185
Epoch 276, current loss (training) 0.0177, current loss (val) 0.0191
Epoch 277, current loss (training) 0.0178, current loss (val) 0.0189
Epoch 278, current loss (training) 0.0187, current loss (val) 0.0191
Epoch 279, current loss (training) 0.0180, current loss (val) 0.0182
Epoch 280, current loss (training) 0.0172, current loss (val) 0.0186
Epoch 281, current loss (training) 0.0174, current loss (val) 0.0187
Epoch 282, current loss (training) 0.0172, current loss (val) 0.0185
Epoch 283, current loss (training) 0.0181, current loss (val) 0.0191
Epoch 284, current loss (training) 0.0189, current loss (val) 0.0207
Epoch 285, current loss (training) 0.0177, current loss (val) 0.0191
Epoch 286, current loss (training) 0.0178, current loss (val) 0.0188
Epoch 287, current loss (training) 0.0181, current loss (val) 0.0192
Epoch 288, current loss (training) 0.0174, current loss (val) 0.0185
Epoch 289, current loss (training) 0.0183, current loss (val) 0.0195
Epoch 290, current loss (training) 0.0179, current loss (val) 0.0187
Epoch 291, current loss (training) 0.0186, current loss (val) 0.0195
Epoch 292, current loss (training) 0.0180, current loss (val) 0.0188
Epoch 293, current loss (training) 0.0176, current loss (val) 0.0190
Epoch 294, current loss (training) 0.0182, current loss (val) 0.0187
Epoch 295, current loss (training) 0.0185, current loss (val) 0.0191
Epoch 296, current loss (training) 0.0177, current loss (val) 0.0189
Epoch 297, current loss (training) 0.0181, current loss (val) 0.0196
Epoch 298, current loss (training) 0.0179, current loss (val) 0.0193
Epoch 299, current loss (training) 0.0170, current loss (val) 0.0185
Epoch 300, current loss (training) 0.0177, current loss (val) 0.0189
Epoch 301, current loss (training) 0.0175, current loss (val) 0.0187
Epoch 302, current loss (training) 0.0180, current loss (val) 0.0190
Epoch 303, current loss (training) 0.0177, current loss (val) 0.0186
Epoch 304, current loss (training) 0.0173, current loss (val) 0.0185
Epoch 305, current loss (training) 0.0176, current loss (val) 0.0189
Epoch 306, current loss (training) 0.0169, current loss (val) 0.0185
Epoch 307, current loss (training) 0.0178, current loss (val) 0.0190
Epoch 308, current loss (training) 0.0181, current loss (val) 0.0191
Epoch 309, current loss (training) 0.0175, current loss (val) 0.0186
Epoch 310, current loss (training) 0.0177, current loss (val) 0.0188
Epoch 311, current loss (training) 0.0178, current loss (val) 0.0188
Epoch 312, current loss (training) 0.0180, current loss (val) 0.0190
Epoch 313, current loss (training) 0.0218, current loss (val) 0.0215
Epoch 314, current loss (training) 0.0175, current loss (val) 0.0190
Epoch 315, current loss (training) 0.0178, current loss (val) 0.0188
Epoch 316, current loss (training) 0.0181, current loss (val) 0.0190
Epoch 317, current loss (training) 0.0175, current loss (val) 0.0185
Epoch 318, current loss (training) 0.0189, current loss (val) 0.0190
Epoch 319, current loss (training) 0.0173, current loss (val) 0.0186
Epoch 320, current loss (training) 0.0180, current loss (val) 0.0187
Epoch 321, current loss (training) 0.0177, current loss (val) 0.0183
Epoch 322, current loss (training) 0.0184, current loss (val) 0.0189
Epoch 323, current loss (training) 0.0185, current loss (val) 0.0196
Epoch 324, current loss (training) 0.0173, current loss (val) 0.0185
Epoch 325, current loss (training) 0.0174, current loss (val) 0.0187
Epoch 326, current loss (training) 0.0177, current loss (val) 0.0189
Epoch 327, current loss (training) 0.0179, current loss (val) 0.0187
Epoch 328, current loss (training) 0.0178, current loss (val) 0.0185
Epoch 329, current loss (training) 0.0176, current loss (val) 0.0188
Epoch 330, current loss (training) 0.0188, current loss (val) 0.0192
Epoch 331, current loss (training) 0.0185, current loss (val) 0.0196
Epoch 332, current loss (training) 0.0176, current loss (val) 0.0188
Epoch 333, current loss (training) 0.0179, current loss (val) 0.0189
Epoch 334, current loss (training) 0.0171, current loss (val) 0.0188
Epoch 335, current loss (training) 0.0180, current loss (val) 0.0190
Epoch 336, current loss (training) 0.0176, current loss (val) 0.0189
Epoch 337, current loss (training) 0.0247, current loss (val) 0.0256
Epoch 338, current loss (training) 0.0176, current loss (val) 0.0185
Epoch 339, current loss (training) 0.0182, current loss (val) 0.0188
Epoch 340, current loss (training) 0.0182, current loss (val) 0.0188
Epoch 341, current loss (training) 0.0180, current loss (val) 0.0189
Epoch 342, current loss (training) 0.0177, current loss (val) 0.0189
Epoch 343, current loss (training) 0.0182, current loss (val) 0.0188
Epoch 344, current loss (training) 0.0178, current loss (val) 0.0186
Epoch 345, current loss (training) 0.0174, current loss (val) 0.0188
Epoch 346, current loss (training) 0.0173, current loss (val) 0.0186
Epoch 347, current loss (training) 0.0176, current loss (val) 0.0186
Epoch 348, current loss (training) 0.0179, current loss (val) 0.0185
Epoch 349, current loss (training) 0.0199, current loss (val) 0.0200
Epoch 350, current loss (training) 0.0187, current loss (val) 0.0195
Epoch 351, current loss (training) 0.0179, current loss (val) 0.0193
Epoch 352, current loss (training) 0.0181, current loss (val) 0.0190
Epoch 353, current loss (training) 0.0175, current loss (val) 0.0187
Epoch 354, current loss (training) 0.0182, current loss (val) 0.0193
Epoch 355, current loss (training) 0.0172, current loss (val) 0.0186
Epoch 356, current loss (training) 0.0178, current loss (val) 0.0191
Epoch 357, current loss (training) 0.0179, current loss (val) 0.0188
Epoch 358, current loss (training) 0.0175, current loss (val) 0.0186
Epoch 359, current loss (training) 0.0180, current loss (val) 0.0193
Epoch 360, current loss (training) 0.0182, current loss (val) 0.0197
Epoch 361, current loss (training) 0.0179, current loss (val) 0.0191
Epoch 362, current loss (training) 0.0177, current loss (val) 0.0185
Epoch 363, current loss (training) 0.0180, current loss (val) 0.0190
Epoch 364, current loss (training) 0.0178, current loss (val) 0.0190
Epoch 365, current loss (training) 0.0183, current loss (val) 0.0189
Epoch 366, current loss (training) 0.0181, current loss (val) 0.0185
Epoch 367, current loss (training) 0.0178, current loss (val) 0.0185
Epoch 368, current loss (training) 0.0181, current loss (val) 0.0188
Epoch 369, current loss (training) 0.0183, current loss (val) 0.0189
Epoch 370, current loss (training) 0.0178, current loss (val) 0.0190
Epoch 371, current loss (training) 0.0172, current loss (val) 0.0185
Epoch 372, current loss (training) 0.0176, current loss (val) 0.0191
Epoch 373, current loss (training) 0.0176, current loss (val) 0.0187
Epoch 374, current loss (training) 0.0180, current loss (val) 0.0186
Epoch 375, current loss (training) 0.0180, current loss (val) 0.0188
Epoch 376, current loss (training) 0.0176, current loss (val) 0.0186
Epoch 377, current loss (training) 0.0174, current loss (val) 0.0189
Epoch 378, current loss (training) 0.0185, current loss (val) 0.0190
Epoch 379, current loss (training) 0.0186, current loss (val) 0.0188
Epoch 380, current loss (training) 0.0176, current loss (val) 0.0191
Epoch 381, current loss (training) 0.0184, current loss (val) 0.0189
Epoch 382, current loss (training) 0.0182, current loss (val) 0.0191
Epoch 383, current loss (training) 0.0178, current loss (val) 0.0191
Epoch 384, current loss (training) 0.0180, current loss (val) 0.0190
Epoch 385, current loss (training) 0.0169, current loss (val) 0.0185
Epoch 386, current loss (training) 0.0168, current loss (val) 0.0185
Epoch 387, current loss (training) 0.0187, current loss (val) 0.0193
Epoch 388, current loss (training) 0.0191, current loss (val) 0.0197
Epoch 389, current loss (training) 0.0169, current loss (val) 0.0186
Epoch 390, current loss (training) 0.0183, current loss (val) 0.0196
Epoch 391, current loss (training) 0.0186, current loss (val) 0.0199
Epoch 392, current loss (training) 0.0173, current loss (val) 0.0184
Epoch 393, current loss (training) 0.0178, current loss (val) 0.0190
Epoch 394, current loss (training) 0.0176, current loss (val) 0.0185
Epoch 395, current loss (training) 0.0170, current loss (val) 0.0186
Epoch 396, current loss (training) 0.0177, current loss (val) 0.0187
Epoch 397, current loss (training) 0.0181, current loss (val) 0.0190
Epoch 398, current loss (training) 0.0180, current loss (val) 0.0191
Epoch 399, current loss (training) 0.0176, current loss (val) 0.0186
Epoch 400, current loss (training) 0.0179, current loss (val) 0.0188
Epoch 401, current loss (training) 0.0186, current loss (val) 0.0198
Epoch 402, current loss (training) 0.0175, current loss (val) 0.0185
Epoch 403, current loss (training) 0.0175, current loss (val) 0.0187
Epoch 404, current loss (training) 0.0181, current loss (val) 0.0192
Epoch 405, current loss (training) 0.0173, current loss (val) 0.0189
Epoch 406, current loss (training) 0.0185, current loss (val) 0.0189
Epoch 407, current loss (training) 0.0184, current loss (val) 0.0188
Epoch 408, current loss (training) 0.0180, current loss (val) 0.0185
Epoch 409, current loss (training) 0.0183, current loss (val) 0.0190
Epoch 410, current loss (training) 0.0178, current loss (val) 0.0189
Epoch 411, current loss (training) 0.0184, current loss (val) 0.0196
Epoch 412, current loss (training) 0.0175, current loss (val) 0.0187
Epoch 413, current loss (training) 0.0170, current loss (val) 0.0185
Epoch 414, current loss (training) 0.0182, current loss (val) 0.0188
Epoch 415, current loss (training) 0.0179, current loss (val) 0.0189
Epoch 416, current loss (training) 0.0176, current loss (val) 0.0187
Epoch 417, current loss (training) 0.0183, current loss (val) 0.0191
Epoch 418, current loss (training) 0.0177, current loss (val) 0.0188
Epoch 419, current loss (training) 0.0177, current loss (val) 0.0185
Epoch 420, current loss (training) 0.0181, current loss (val) 0.0190
Epoch 421, current loss (training) 0.0183, current loss (val) 0.0187
Epoch 422, current loss (training) 0.0176, current loss (val) 0.0188
Epoch 423, current loss (training) 0.0168, current loss (val) 0.0187
Epoch 424, current loss (training) 0.0177, current loss (val) 0.0187
Epoch 425, current loss (training) 0.0179, current loss (val) 0.0188
Epoch 426, current loss (training) 0.0180, current loss (val) 0.0194
Epoch 427, current loss (training) 0.0172, current loss (val) 0.0188
Epoch 428, current loss (training) 0.0177, current loss (val) 0.0187
Epoch 429, current loss (training) 0.0179, current loss (val) 0.0187
Epoch 430, current loss (training) 0.0179, current loss (val) 0.0192
Epoch 431, current loss (training) 0.0187, current loss (val) 0.0194
Epoch 432, current loss (training) 0.0178, current loss (val) 0.0189
Epoch 433, current loss (training) 0.0179, current loss (val) 0.0185
Epoch 434, current loss (training) 0.0179, current loss (val) 0.0187
Epoch 435, current loss (training) 0.0179, current loss (val) 0.0191
Epoch 436, current loss (training) 0.0175, current loss (val) 0.0185
Epoch 437, current loss (training) 0.0178, current loss (val) 0.0186
Epoch 438, current loss (training) 0.0172, current loss (val) 0.0187
Epoch 439, current loss (training) 0.0177, current loss (val) 0.0191
Epoch 440, current loss (training) 0.0170, current loss (val) 0.0183
Epoch 441, current loss (training) 0.0173, current loss (val) 0.0185
Epoch 442, current loss (training) 0.0179, current loss (val) 0.0191
Epoch 443, current loss (training) 0.0179, current loss (val) 0.0192
Epoch 444, current loss (training) 0.0176, current loss (val) 0.0184
Epoch 445, current loss (training) 0.0177, current loss (val) 0.0187
Epoch 446, current loss (training) 0.0180, current loss (val) 0.0188
Epoch 447, current loss (training) 0.0176, current loss (val) 0.0187
Epoch 448, current loss (training) 0.0178, current loss (val) 0.0188
Epoch 449, current loss (training) 0.0177, current loss (val) 0.0187
Epoch 450, current loss (training) 0.0174, current loss (val) 0.0186
Epoch 451, current loss (training) 0.0176, current loss (val) 0.0188
Epoch 452, current loss (training) 0.0174, current loss (val) 0.0190
Epoch 453, current loss (training) 0.0173, current loss (val) 0.0187
Epoch 454, current loss (training) 0.0180, current loss (val) 0.0189
Epoch 455, current loss (training) 0.0173, current loss (val) 0.0184
Epoch 456, current loss (training) 0.0178, current loss (val) 0.0189
Epoch 457, current loss (training) 0.0179, current loss (val) 0.0189
Epoch 458, current loss (training) 0.0175, current loss (val) 0.0188
Epoch 459, current loss (training) 0.0172, current loss (val) 0.0185
Epoch 460, current loss (training) 0.0174, current loss (val) 0.0186
Epoch 461, current loss (training) 0.0189, current loss (val) 0.0190
Epoch 462, current loss (training) 0.0175, current loss (val) 0.0185
Epoch 463, current loss (training) 0.0177, current loss (val) 0.0187
Epoch 464, current loss (training) 0.0167, current loss (val) 0.0187
Epoch 465, current loss (training) 0.0176, current loss (val) 0.0186
Epoch 466, current loss (training) 0.0174, current loss (val) 0.0186
Epoch 467, current loss (training) 0.0183, current loss (val) 0.0189
Epoch 468, current loss (training) 0.0169, current loss (val) 0.0185
Epoch 469, current loss (training) 0.0182, current loss (val) 0.0190
Epoch 470, current loss (training) 0.0174, current loss (val) 0.0186
Epoch 471, current loss (training) 0.0183, current loss (val) 0.0189
Epoch 472, current loss (training) 0.0171, current loss (val) 0.0186
Epoch 473, current loss (training) 0.0195, current loss (val) 0.0204
Epoch 474, current loss (training) 0.0206, current loss (val) 0.0197
Epoch 475, current loss (training) 0.0171, current loss (val) 0.0187
Epoch 476, current loss (training) 0.0188, current loss (val) 0.0203
Epoch 477, current loss (training) 0.0177, current loss (val) 0.0189
Epoch 478, current loss (training) 0.0175, current loss (val) 0.0186
Epoch 479, current loss (training) 0.0184, current loss (val) 0.0186
Epoch 480, current loss (training) 0.0171, current loss (val) 0.0187
Epoch 481, current loss (training) 0.0171, current loss (val) 0.0186
Epoch 482, current loss (training) 0.0179, current loss (val) 0.0185
Epoch 483, current loss (training) 0.0185, current loss (val) 0.0189
Epoch 484, current loss (training) 0.0174, current loss (val) 0.0186
Epoch 485, current loss (training) 0.0172, current loss (val) 0.0185
Epoch 486, current loss (training) 0.0172, current loss (val) 0.0187
Epoch 487, current loss (training) 0.0181, current loss (val) 0.0192
Epoch 488, current loss (training) 0.0174, current loss (val) 0.0186
Epoch 489, current loss (training) 0.0177, current loss (val) 0.0186
Epoch 490, current loss (training) 0.0173, current loss (val) 0.0191
Epoch 491, current loss (training) 0.0183, current loss (val) 0.0192
Epoch 492, current loss (training) 0.0181, current loss (val) 0.0189
Epoch 493, current loss (training) 0.0184, current loss (val) 0.0193
Epoch 494, current loss (training) 0.0168, current loss (val) 0.0185
Epoch 495, current loss (training) 0.0177, current loss (val) 0.0186
Epoch 496, current loss (training) 0.0201, current loss (val) 0.0201
Epoch 497, current loss (training) 0.0174, current loss (val) 0.0186
Epoch 498, current loss (training) 0.0181, current loss (val) 0.0189
Epoch 499, current loss (training) 0.0183, current loss (val) 0.0195
Epoch 500, current loss (training) 0.0190, current loss (val) 0.0198
run_time_first_training_cycle:  3860.94 

Epochs 500, batch size, 200
Nbr training obs 1000000, nbr parameters 25352, obs/parameters 39.44

Starting abc-rs
Percentage done:  2.00 %
Percentage done:  4.00 %
Percentage done:  6.00 %
Percentage done:  8.00 %
Percentage done:  10.00 %
Percentage done:  12.00 %
Percentage done:  14.00 %
Percentage done:  16.00 %
Percentage done:  18.00 %
Percentage done:  20.00 %
Percentage done:  22.00 %
Percentage done:  24.00 %
Percentage done:  26.00 %
Percentage done:  28.00 %
Percentage done:  30.00 %
Percentage done:  32.00 %
Percentage done:  34.00 %
Percentage done:  36.00 %
Percentage done:  38.00 %
Percentage done:  40.00 %
Percentage done:  42.00 %
Percentage done:  44.00 %
Percentage done:  46.00 %
Percentage done:  48.00 %
Percentage done:  50.00 %
Percentage done:  52.00 %
Percentage done:  54.00 %
Percentage done:  56.00 %
Percentage done:  58.00 %
Percentage done:  60.00 %
Percentage done:  62.00 %
Percentage done:  64.00 %
Percentage done:  66.00 %
Percentage done:  68.00 %
Percentage done:  70.00 %
Percentage done:  72.00 %
Percentage done:  74.00 %
Percentage done:  76.00 %
Percentage done:  78.00 %
Percentage done:  80.00 %
Percentage done:  82.00 %
Percentage done:  84.00 %
Percentage done:  86.00 %
Percentage done:  88.00 %
Percentage done:  90.00 %
Percentage done:  92.00 %
Percentage done:  94.00 %
Percentage done:  96.00 %
Percentage done:  98.00 %
Percentage done:  100.00 %
Ending abc-rs
 70.548031 seconds (14.87 M allocations: 2.001 GiB, 0.55% gc time)
end script
