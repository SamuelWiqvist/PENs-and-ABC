Wed Nov  7 18:45:06 2018       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 396.44                 Driver Version: 396.44                    |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|===============================+======================+======================|
|   0  Tesla K80           On   | 00000000:04:00.0 Off |                    0 |
| N/A   42C    P0    92W / 149W |   9916MiB / 11441MiB |     27%      Default |
+-------------------------------+----------------------+----------------------+
|   1  Tesla K80           On   | 00000000:05:00.0 Off |                    0 |
| N/A   34C    P8    32W / 149W |      0MiB / 11441MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
|   2  Tesla K80           On   | 00000000:84:00.0 Off |                    0 |
| N/A   25C    P8    26W / 149W |      0MiB / 11441MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
|   3  Tesla K80           On   | 00000000:85:00.0 Off |                    0 |
| N/A   32C    P8    30W / 149W |      0MiB / 11441MiB |      0%      Default |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                       GPU Memory |
|  GPU       PID   Type   Process name                             Usage      |
|=============================================================================|
|    0     72879      C   julia                                       9903MiB |
+-----------------------------------------------------------------------------+
/home/samwiq/ABC and deep learning project/abc-dl/lunarc
/home/samwiq/ABC and deep learning project/abc-dl
start script
DNN_simple
standard
500
1
1
check version of Knet
    Status `~/.julia/environments/v1.0/Project.toml`
  [336ed68f] CSV v0.3.1
  [a93c6f00] DataFrames v0.13.1
  [31c24e10] Distributions v0.16.4
  [1902f260] Knet v1.1.0
  [6f286f6a] MultivariateStats v0.6.0 #master (https://github.com/JuliaStats/MultivariateStats.jl.git)
  [2913bbd2] StatsBase v0.25.0
  [4c63d2b9] StatsFuns v0.7.0
build Knet
  Building SpecialFunctions → `~/.julia/packages/SpecialFunctions/KvXoO/deps/build.log`
  Building CodecZlib ───────→ `~/.julia/packages/CodecZlib/wwgbh/deps/build.log`
  Building Knet ────────────→ `~/.julia/packages/Knet/hxjeS/deps/build.log`
test gpu
4
-1
0
Loading AR2 model
Starting: generate_parameter_data_pairs
Percentage done:  0.77 %
Percentage done:  1.54 %
Percentage done:  2.31 %
Percentage done:  3.08 %
Percentage done:  3.85 %
Percentage done:  4.62 %
Percentage done:  5.38 %
Percentage done:  6.15 %
Percentage done:  6.92 %
Percentage done:  7.69 %
Percentage done:  8.46 %
Percentage done:  9.23 %
Percentage done:  10.00 %
Percentage done:  10.77 %
Percentage done:  11.54 %
Percentage done:  12.31 %
Percentage done:  13.08 %
Percentage done:  13.85 %
Percentage done:  14.62 %
Percentage done:  15.38 %
Percentage done:  16.15 %
Percentage done:  16.92 %
Percentage done:  17.69 %
Percentage done:  18.46 %
Percentage done:  19.23 %
Percentage done:  20.00 %
Percentage done:  20.77 %
Percentage done:  21.54 %
Percentage done:  22.31 %
Percentage done:  23.08 %
Percentage done:  23.85 %
Percentage done:  24.62 %
Percentage done:  25.38 %
Percentage done:  26.15 %
Percentage done:  26.92 %
Percentage done:  27.69 %
Percentage done:  28.46 %
Percentage done:  29.23 %
Percentage done:  30.00 %
Percentage done:  30.77 %
Percentage done:  31.54 %
Percentage done:  32.31 %
Percentage done:  33.08 %
Percentage done:  33.85 %
Percentage done:  34.62 %
Percentage done:  35.38 %
Percentage done:  36.15 %
Percentage done:  36.92 %
Percentage done:  37.69 %
Percentage done:  38.46 %
Percentage done:  39.23 %
Percentage done:  40.00 %
Percentage done:  40.77 %
Percentage done:  41.54 %
Percentage done:  42.31 %
Percentage done:  43.08 %
Percentage done:  43.85 %
Percentage done:  44.62 %
Percentage done:  45.38 %
Percentage done:  46.15 %
Percentage done:  46.92 %
Percentage done:  47.69 %
Percentage done:  48.46 %
Percentage done:  49.23 %
Percentage done:  50.00 %
Percentage done:  50.77 %
Percentage done:  51.54 %
Percentage done:  52.31 %
Percentage done:  53.08 %
Percentage done:  53.85 %
Percentage done:  54.62 %
Percentage done:  55.38 %
Percentage done:  56.15 %
Percentage done:  56.92 %
Percentage done:  57.69 %
Percentage done:  58.46 %
Percentage done:  59.23 %
Percentage done:  60.00 %
Percentage done:  60.77 %
Percentage done:  61.54 %
Percentage done:  62.31 %
Percentage done:  63.08 %
Percentage done:  63.85 %
Percentage done:  64.62 %
Percentage done:  65.38 %
Percentage done:  66.15 %
Percentage done:  66.92 %
Percentage done:  67.69 %
Percentage done:  68.46 %
Percentage done:  69.23 %
Percentage done:  70.00 %
Percentage done:  70.77 %
Percentage done:  71.54 %
Percentage done:  72.31 %
Percentage done:  73.08 %
Percentage done:  73.85 %
Percentage done:  74.62 %
Percentage done:  75.38 %
Percentage done:  76.15 %
Percentage done:  76.92 %
Percentage done:  77.69 %
Percentage done:  78.46 %
Percentage done:  79.23 %
Percentage done:  80.00 %
Percentage done:  80.77 %
Percentage done:  81.54 %
Percentage done:  82.31 %
Percentage done:  83.08 %
Percentage done:  83.85 %
Percentage done:  84.62 %
Percentage done:  85.38 %
Percentage done:  86.15 %
Percentage done:  86.92 %
Percentage done:  87.69 %
Percentage done:  88.46 %
Percentage done:  89.23 %
Percentage done:  90.00 %
Percentage done:  90.77 %
Percentage done:  91.54 %
Percentage done:  92.31 %
Percentage done:  93.08 %
Percentage done:  93.85 %
Percentage done:  94.62 %
Percentage done:  95.38 %
Percentage done:  96.15 %
Percentage done:  96.92 %
Percentage done:  97.69 %
Percentage done:  98.46 %
Percentage done:  99.23 %
Percentage done:  100.00 %
Nbr training obs 1000000, nbr parameters 25352, obs/parameters 39.44
0
Starting training
Epoch 1, current loss (training) 0.2100, current loss (val) 0.2191
Epoch 2, current loss (training) 0.0585, current loss (val) 0.0606
Epoch 3, current loss (training) 0.0377, current loss (val) 0.0376
Epoch 4, current loss (training) 0.0301, current loss (val) 0.0310
Epoch 5, current loss (training) 0.0262, current loss (val) 0.0274
Epoch 6, current loss (training) 0.0234, current loss (val) 0.0238
Epoch 7, current loss (training) 0.0227, current loss (val) 0.0235
Epoch 8, current loss (training) 0.0241, current loss (val) 0.0244
Epoch 9, current loss (training) 0.0207, current loss (val) 0.0213
Epoch 10, current loss (training) 0.0209, current loss (val) 0.0218
Epoch 11, current loss (training) 0.0207, current loss (val) 0.0220
Epoch 12, current loss (training) 0.0203, current loss (val) 0.0214
Epoch 13, current loss (training) 0.0202, current loss (val) 0.0209
Epoch 14, current loss (training) 0.0255, current loss (val) 0.0271
Epoch 15, current loss (training) 0.0202, current loss (val) 0.0206
Epoch 16, current loss (training) 0.0227, current loss (val) 0.0225
Epoch 17, current loss (training) 0.0197, current loss (val) 0.0207
Epoch 18, current loss (training) 0.0194, current loss (val) 0.0203
Epoch 19, current loss (training) 0.0223, current loss (val) 0.0235
Epoch 20, current loss (training) 0.0194, current loss (val) 0.0203
Epoch 21, current loss (training) 0.0192, current loss (val) 0.0203
Epoch 22, current loss (training) 0.0195, current loss (val) 0.0207
Epoch 23, current loss (training) 0.0192, current loss (val) 0.0197
Epoch 24, current loss (training) 0.0194, current loss (val) 0.0196
Epoch 25, current loss (training) 0.0192, current loss (val) 0.0200
Epoch 26, current loss (training) 0.0192, current loss (val) 0.0197
Epoch 27, current loss (training) 0.0190, current loss (val) 0.0197
Epoch 28, current loss (training) 0.0199, current loss (val) 0.0210
Epoch 29, current loss (training) 0.0188, current loss (val) 0.0194
Epoch 30, current loss (training) 0.0191, current loss (val) 0.0200
Epoch 31, current loss (training) 0.0185, current loss (val) 0.0195
Epoch 32, current loss (training) 0.0195, current loss (val) 0.0202
Epoch 33, current loss (training) 0.0187, current loss (val) 0.0195
Epoch 34, current loss (training) 0.0188, current loss (val) 0.0193
Epoch 35, current loss (training) 0.0187, current loss (val) 0.0192
Epoch 36, current loss (training) 0.0183, current loss (val) 0.0193
Epoch 37, current loss (training) 0.0183, current loss (val) 0.0196
Epoch 38, current loss (training) 0.0195, current loss (val) 0.0201
Epoch 39, current loss (training) 0.0186, current loss (val) 0.0198
Epoch 40, current loss (training) 0.0184, current loss (val) 0.0192
Epoch 41, current loss (training) 0.0189, current loss (val) 0.0193
Epoch 42, current loss (training) 0.0188, current loss (val) 0.0196
Epoch 43, current loss (training) 0.0189, current loss (val) 0.0193
Epoch 44, current loss (training) 0.0185, current loss (val) 0.0198
Epoch 45, current loss (training) 0.0182, current loss (val) 0.0191
Epoch 46, current loss (training) 0.0182, current loss (val) 0.0192
Epoch 47, current loss (training) 0.0187, current loss (val) 0.0194
Epoch 48, current loss (training) 0.0183, current loss (val) 0.0191
Epoch 49, current loss (training) 0.0190, current loss (val) 0.0195
Epoch 50, current loss (training) 0.0184, current loss (val) 0.0192
Epoch 51, current loss (training) 0.0179, current loss (val) 0.0191
Epoch 52, current loss (training) 0.0185, current loss (val) 0.0194
Epoch 53, current loss (training) 0.0185, current loss (val) 0.0192
Epoch 54, current loss (training) 0.0180, current loss (val) 0.0189
Epoch 55, current loss (training) 0.0183, current loss (val) 0.0188
Epoch 56, current loss (training) 0.0204, current loss (val) 0.0208
Epoch 57, current loss (training) 0.0189, current loss (val) 0.0195
Epoch 58, current loss (training) 0.0182, current loss (val) 0.0192
Epoch 59, current loss (training) 0.0190, current loss (val) 0.0195
Epoch 60, current loss (training) 0.0176, current loss (val) 0.0192
Epoch 61, current loss (training) 0.0184, current loss (val) 0.0189
Epoch 62, current loss (training) 0.0180, current loss (val) 0.0193
Epoch 63, current loss (training) 0.0184, current loss (val) 0.0191
Epoch 64, current loss (training) 0.0191, current loss (val) 0.0192
Epoch 65, current loss (training) 0.0188, current loss (val) 0.0198
Epoch 66, current loss (training) 0.0190, current loss (val) 0.0191
Epoch 67, current loss (training) 0.0188, current loss (val) 0.0197
Epoch 68, current loss (training) 0.0180, current loss (val) 0.0195
Epoch 69, current loss (training) 0.0185, current loss (val) 0.0195
Epoch 70, current loss (training) 0.0180, current loss (val) 0.0190
Epoch 71, current loss (training) 0.0178, current loss (val) 0.0191
Epoch 72, current loss (training) 0.0184, current loss (val) 0.0193
Epoch 73, current loss (training) 0.0189, current loss (val) 0.0192
Epoch 74, current loss (training) 0.0186, current loss (val) 0.0193
Epoch 75, current loss (training) 0.0185, current loss (val) 0.0192
Epoch 76, current loss (training) 0.0183, current loss (val) 0.0187
Epoch 77, current loss (training) 0.0184, current loss (val) 0.0191
Epoch 78, current loss (training) 0.0175, current loss (val) 0.0186
Epoch 79, current loss (training) 0.0184, current loss (val) 0.0190
Epoch 80, current loss (training) 0.0182, current loss (val) 0.0191
Epoch 81, current loss (training) 0.0222, current loss (val) 0.0220
Epoch 82, current loss (training) 0.0180, current loss (val) 0.0195
Epoch 83, current loss (training) 0.0176, current loss (val) 0.0190
Epoch 84, current loss (training) 0.0184, current loss (val) 0.0190
Epoch 85, current loss (training) 0.0181, current loss (val) 0.0190
Epoch 86, current loss (training) 0.0175, current loss (val) 0.0189
Epoch 87, current loss (training) 0.0185, current loss (val) 0.0189
Epoch 88, current loss (training) 0.0178, current loss (val) 0.0187
Epoch 89, current loss (training) 0.0188, current loss (val) 0.0190
Epoch 90, current loss (training) 0.0191, current loss (val) 0.0195
Epoch 91, current loss (training) 0.0183, current loss (val) 0.0192
Epoch 92, current loss (training) 0.0191, current loss (val) 0.0192
Epoch 93, current loss (training) 0.0190, current loss (val) 0.0195
Epoch 94, current loss (training) 0.0181, current loss (val) 0.0189
Epoch 95, current loss (training) 0.0185, current loss (val) 0.0191
Epoch 96, current loss (training) 0.0183, current loss (val) 0.0191
Epoch 97, current loss (training) 0.0177, current loss (val) 0.0186
Epoch 98, current loss (training) 0.0188, current loss (val) 0.0194
Epoch 99, current loss (training) 0.0186, current loss (val) 0.0190
Epoch 100, current loss (training) 0.0182, current loss (val) 0.0190
Epoch 101, current loss (training) 0.0181, current loss (val) 0.0189
Epoch 102, current loss (training) 0.0189, current loss (val) 0.0189
Epoch 103, current loss (training) 0.0202, current loss (val) 0.0209
Epoch 104, current loss (training) 0.0178, current loss (val) 0.0188
Epoch 105, current loss (training) 0.0187, current loss (val) 0.0192
Epoch 106, current loss (training) 0.0179, current loss (val) 0.0190
Epoch 107, current loss (training) 0.0186, current loss (val) 0.0190
Epoch 108, current loss (training) 0.0190, current loss (val) 0.0195
Epoch 109, current loss (training) 0.0177, current loss (val) 0.0187
Epoch 110, current loss (training) 0.0181, current loss (val) 0.0189
Epoch 111, current loss (training) 0.0180, current loss (val) 0.0189
Epoch 112, current loss (training) 0.0177, current loss (val) 0.0187
Epoch 113, current loss (training) 0.0180, current loss (val) 0.0191
Epoch 114, current loss (training) 0.0213, current loss (val) 0.0216
Epoch 115, current loss (training) 0.0180, current loss (val) 0.0189
Epoch 116, current loss (training) 0.0183, current loss (val) 0.0190
Epoch 117, current loss (training) 0.0179, current loss (val) 0.0192
Epoch 118, current loss (training) 0.0175, current loss (val) 0.0189
Epoch 119, current loss (training) 0.0182, current loss (val) 0.0196
Epoch 120, current loss (training) 0.0181, current loss (val) 0.0187
Epoch 121, current loss (training) 0.0178, current loss (val) 0.0186
Epoch 122, current loss (training) 0.0181, current loss (val) 0.0189
Epoch 123, current loss (training) 0.0186, current loss (val) 0.0195
Epoch 124, current loss (training) 0.0184, current loss (val) 0.0190
Epoch 125, current loss (training) 0.0182, current loss (val) 0.0186
Epoch 126, current loss (training) 0.0180, current loss (val) 0.0190
Epoch 127, current loss (training) 0.0174, current loss (val) 0.0186
Epoch 128, current loss (training) 0.0176, current loss (val) 0.0187
Epoch 129, current loss (training) 0.0192, current loss (val) 0.0207
Epoch 130, current loss (training) 0.0186, current loss (val) 0.0195
Epoch 131, current loss (training) 0.0183, current loss (val) 0.0189
Epoch 132, current loss (training) 0.0174, current loss (val) 0.0187
Epoch 133, current loss (training) 0.0177, current loss (val) 0.0192
Epoch 134, current loss (training) 0.0185, current loss (val) 0.0197
Epoch 135, current loss (training) 0.0178, current loss (val) 0.0189
Epoch 136, current loss (training) 0.0184, current loss (val) 0.0189
Epoch 137, current loss (training) 0.0178, current loss (val) 0.0193
Epoch 138, current loss (training) 0.0182, current loss (val) 0.0188
Epoch 139, current loss (training) 0.0177, current loss (val) 0.0189
Epoch 140, current loss (training) 0.0179, current loss (val) 0.0187
Epoch 141, current loss (training) 0.0177, current loss (val) 0.0188
Epoch 142, current loss (training) 0.0214, current loss (val) 0.0223
Epoch 143, current loss (training) 0.0176, current loss (val) 0.0185
Epoch 144, current loss (training) 0.0179, current loss (val) 0.0188
Epoch 145, current loss (training) 0.0182, current loss (val) 0.0189
Epoch 146, current loss (training) 0.0179, current loss (val) 0.0187
Epoch 147, current loss (training) 0.0195, current loss (val) 0.0195
Epoch 148, current loss (training) 0.0191, current loss (val) 0.0195
Epoch 149, current loss (training) 0.0178, current loss (val) 0.0187
Epoch 150, current loss (training) 0.0179, current loss (val) 0.0191
Epoch 151, current loss (training) 0.0176, current loss (val) 0.0186
Epoch 152, current loss (training) 0.0177, current loss (val) 0.0188
Epoch 153, current loss (training) 0.0181, current loss (val) 0.0186
Epoch 154, current loss (training) 0.0193, current loss (val) 0.0197
Epoch 155, current loss (training) 0.0182, current loss (val) 0.0185
Epoch 156, current loss (training) 0.0180, current loss (val) 0.0191
Epoch 157, current loss (training) 0.0179, current loss (val) 0.0187
Epoch 158, current loss (training) 0.0175, current loss (val) 0.0185
Epoch 159, current loss (training) 0.0182, current loss (val) 0.0193
Epoch 160, current loss (training) 0.0204, current loss (val) 0.0210
Epoch 161, current loss (training) 0.0177, current loss (val) 0.0190
Epoch 162, current loss (training) 0.0179, current loss (val) 0.0193
Epoch 163, current loss (training) 0.0178, current loss (val) 0.0188
Epoch 164, current loss (training) 0.0209, current loss (val) 0.0213
Epoch 165, current loss (training) 0.0176, current loss (val) 0.0187
Epoch 166, current loss (training) 0.0177, current loss (val) 0.0188
Epoch 167, current loss (training) 0.0174, current loss (val) 0.0190
Epoch 168, current loss (training) 0.0172, current loss (val) 0.0189
Epoch 169, current loss (training) 0.0179, current loss (val) 0.0193
Epoch 170, current loss (training) 0.0176, current loss (val) 0.0187
Epoch 171, current loss (training) 0.0180, current loss (val) 0.0186
Epoch 172, current loss (training) 0.0185, current loss (val) 0.0193
Epoch 173, current loss (training) 0.0186, current loss (val) 0.0194
Epoch 174, current loss (training) 0.0185, current loss (val) 0.0191
Epoch 175, current loss (training) 0.0187, current loss (val) 0.0193
Epoch 176, current loss (training) 0.0172, current loss (val) 0.0188
Epoch 177, current loss (training) 0.0183, current loss (val) 0.0186
Epoch 178, current loss (training) 0.0180, current loss (val) 0.0186
Epoch 179, current loss (training) 0.0181, current loss (val) 0.0194
Epoch 180, current loss (training) 0.0179, current loss (val) 0.0187
Epoch 181, current loss (training) 0.0176, current loss (val) 0.0185
Epoch 182, current loss (training) 0.0173, current loss (val) 0.0186
Epoch 183, current loss (training) 0.0184, current loss (val) 0.0187
Epoch 184, current loss (training) 0.0177, current loss (val) 0.0189
Epoch 185, current loss (training) 0.0181, current loss (val) 0.0193
Epoch 186, current loss (training) 0.0185, current loss (val) 0.0191
Epoch 187, current loss (training) 0.0180, current loss (val) 0.0187
Epoch 188, current loss (training) 0.0177, current loss (val) 0.0193
Epoch 189, current loss (training) 0.0180, current loss (val) 0.0187
Epoch 190, current loss (training) 0.0175, current loss (val) 0.0184
Epoch 191, current loss (training) 0.0176, current loss (val) 0.0188
Epoch 192, current loss (training) 0.0183, current loss (val) 0.0189
Epoch 193, current loss (training) 0.0181, current loss (val) 0.0184
Epoch 194, current loss (training) 0.0184, current loss (val) 0.0188
Epoch 195, current loss (training) 0.0180, current loss (val) 0.0187
Epoch 196, current loss (training) 0.0178, current loss (val) 0.0186
Epoch 197, current loss (training) 0.0176, current loss (val) 0.0189
Epoch 198, current loss (training) 0.0176, current loss (val) 0.0184
Epoch 199, current loss (training) 0.0174, current loss (val) 0.0190
Epoch 200, current loss (training) 0.0175, current loss (val) 0.0189
Epoch 201, current loss (training) 0.0176, current loss (val) 0.0188
Epoch 202, current loss (training) 0.0178, current loss (val) 0.0186
Epoch 203, current loss (training) 0.0180, current loss (val) 0.0191
Epoch 204, current loss (training) 0.0181, current loss (val) 0.0196
Epoch 205, current loss (training) 0.0184, current loss (val) 0.0189
Epoch 206, current loss (training) 0.0186, current loss (val) 0.0198
Epoch 207, current loss (training) 0.0174, current loss (val) 0.0189
Epoch 208, current loss (training) 0.0183, current loss (val) 0.0186
Epoch 209, current loss (training) 0.0182, current loss (val) 0.0187
Epoch 210, current loss (training) 0.0180, current loss (val) 0.0185
Epoch 211, current loss (training) 0.0179, current loss (val) 0.0191
Epoch 212, current loss (training) 0.0191, current loss (val) 0.0198
Epoch 213, current loss (training) 0.0188, current loss (val) 0.0186
Epoch 214, current loss (training) 0.0183, current loss (val) 0.0194
Epoch 215, current loss (training) 0.0174, current loss (val) 0.0189
Epoch 216, current loss (training) 0.0175, current loss (val) 0.0189
Epoch 217, current loss (training) 0.0178, current loss (val) 0.0188
Epoch 218, current loss (training) 0.0185, current loss (val) 0.0189
Epoch 219, current loss (training) 0.0181, current loss (val) 0.0191
Epoch 220, current loss (training) 0.0176, current loss (val) 0.0187
Epoch 221, current loss (training) 0.0178, current loss (val) 0.0190
Epoch 222, current loss (training) 0.0172, current loss (val) 0.0186
Epoch 223, current loss (training) 0.0177, current loss (val) 0.0187
Epoch 224, current loss (training) 0.0179, current loss (val) 0.0187
Epoch 225, current loss (training) 0.0183, current loss (val) 0.0191
Epoch 226, current loss (training) 0.0186, current loss (val) 0.0193
Epoch 227, current loss (training) 0.0188, current loss (val) 0.0190
Epoch 228, current loss (training) 0.0185, current loss (val) 0.0193
Epoch 229, current loss (training) 0.0172, current loss (val) 0.0185
Epoch 230, current loss (training) 0.0185, current loss (val) 0.0190
Epoch 231, current loss (training) 0.0181, current loss (val) 0.0187
Epoch 232, current loss (training) 0.0179, current loss (val) 0.0187
Epoch 233, current loss (training) 0.0187, current loss (val) 0.0197
Epoch 234, current loss (training) 0.0176, current loss (val) 0.0186
Epoch 235, current loss (training) 0.0186, current loss (val) 0.0192
Epoch 236, current loss (training) 0.0176, current loss (val) 0.0190
Epoch 237, current loss (training) 0.0171, current loss (val) 0.0185
Epoch 238, current loss (training) 0.0174, current loss (val) 0.0186
Epoch 239, current loss (training) 0.0181, current loss (val) 0.0195
Epoch 240, current loss (training) 0.0179, current loss (val) 0.0185
Epoch 241, current loss (training) 0.0175, current loss (val) 0.0189
Epoch 242, current loss (training) 0.0175, current loss (val) 0.0186
Epoch 243, current loss (training) 0.0181, current loss (val) 0.0185
Epoch 244, current loss (training) 0.0178, current loss (val) 0.0190
Epoch 245, current loss (training) 0.0180, current loss (val) 0.0186
Epoch 246, current loss (training) 0.0181, current loss (val) 0.0191
Epoch 247, current loss (training) 0.0191, current loss (val) 0.0200
Epoch 248, current loss (training) 0.0177, current loss (val) 0.0191
Epoch 249, current loss (training) 0.0198, current loss (val) 0.0212
Epoch 250, current loss (training) 0.0183, current loss (val) 0.0187
Epoch 251, current loss (training) 0.0237, current loss (val) 0.0260
Epoch 252, current loss (training) 0.0181, current loss (val) 0.0184
Epoch 253, current loss (training) 0.0176, current loss (val) 0.0185
Epoch 254, current loss (training) 0.0184, current loss (val) 0.0191
Epoch 255, current loss (training) 0.0180, current loss (val) 0.0189
Epoch 256, current loss (training) 0.0179, current loss (val) 0.0187
Epoch 257, current loss (training) 0.0205, current loss (val) 0.0217
Epoch 258, current loss (training) 0.0186, current loss (val) 0.0197
Epoch 259, current loss (training) 0.0178, current loss (val) 0.0184
Epoch 260, current loss (training) 0.0176, current loss (val) 0.0186
Epoch 261, current loss (training) 0.0176, current loss (val) 0.0187
Epoch 262, current loss (training) 0.0183, current loss (val) 0.0188
Epoch 263, current loss (training) 0.0174, current loss (val) 0.0186
Epoch 264, current loss (training) 0.0178, current loss (val) 0.0186
Epoch 265, current loss (training) 0.0178, current loss (val) 0.0188
Epoch 266, current loss (training) 0.0183, current loss (val) 0.0191
Epoch 267, current loss (training) 0.0181, current loss (val) 0.0185
Epoch 268, current loss (training) 0.0179, current loss (val) 0.0190
Epoch 269, current loss (training) 0.0168, current loss (val) 0.0185
Epoch 270, current loss (training) 0.0183, current loss (val) 0.0192
Epoch 271, current loss (training) 0.0177, current loss (val) 0.0190
Epoch 272, current loss (training) 0.0173, current loss (val) 0.0185
Epoch 273, current loss (training) 0.0174, current loss (val) 0.0188
Epoch 274, current loss (training) 0.0180, current loss (val) 0.0189
Epoch 275, current loss (training) 0.0181, current loss (val) 0.0186
Epoch 276, current loss (training) 0.0171, current loss (val) 0.0184
Epoch 277, current loss (training) 0.0179, current loss (val) 0.0185
Epoch 278, current loss (training) 0.0181, current loss (val) 0.0187
Epoch 279, current loss (training) 0.0192, current loss (val) 0.0194
Epoch 280, current loss (training) 0.0185, current loss (val) 0.0189
Epoch 281, current loss (training) 0.0182, current loss (val) 0.0188
Epoch 282, current loss (training) 0.0183, current loss (val) 0.0189
Epoch 283, current loss (training) 0.0187, current loss (val) 0.0194
Epoch 284, current loss (training) 0.0179, current loss (val) 0.0189
Epoch 285, current loss (training) 0.0184, current loss (val) 0.0191
Epoch 286, current loss (training) 0.0177, current loss (val) 0.0187
Epoch 287, current loss (training) 0.0176, current loss (val) 0.0185
Epoch 288, current loss (training) 0.0178, current loss (val) 0.0186
Epoch 289, current loss (training) 0.0188, current loss (val) 0.0193
Epoch 290, current loss (training) 0.0170, current loss (val) 0.0186
Epoch 291, current loss (training) 0.0177, current loss (val) 0.0190
Epoch 292, current loss (training) 0.0200, current loss (val) 0.0206
Epoch 293, current loss (training) 0.0172, current loss (val) 0.0184
Epoch 294, current loss (training) 0.0193, current loss (val) 0.0196
Epoch 295, current loss (training) 0.0177, current loss (val) 0.0188
Epoch 296, current loss (training) 0.0173, current loss (val) 0.0186
Epoch 297, current loss (training) 0.0171, current loss (val) 0.0183
Epoch 298, current loss (training) 0.0180, current loss (val) 0.0193
Epoch 299, current loss (training) 0.0178, current loss (val) 0.0185
Epoch 300, current loss (training) 0.0178, current loss (val) 0.0186
Epoch 301, current loss (training) 0.0183, current loss (val) 0.0190
Epoch 302, current loss (training) 0.0182, current loss (val) 0.0187
Epoch 303, current loss (training) 0.0175, current loss (val) 0.0187
Epoch 304, current loss (training) 0.0177, current loss (val) 0.0184
Epoch 305, current loss (training) 0.0199, current loss (val) 0.0203
Epoch 306, current loss (training) 0.0179, current loss (val) 0.0188
Epoch 307, current loss (training) 0.0208, current loss (val) 0.0224
Epoch 308, current loss (training) 0.0176, current loss (val) 0.0186
Epoch 309, current loss (training) 0.0175, current loss (val) 0.0185
Epoch 310, current loss (training) 0.0180, current loss (val) 0.0187
Epoch 311, current loss (training) 0.0179, current loss (val) 0.0186
Epoch 312, current loss (training) 0.0175, current loss (val) 0.0188
Epoch 313, current loss (training) 0.0182, current loss (val) 0.0187
Epoch 314, current loss (training) 0.0174, current loss (val) 0.0184
Epoch 315, current loss (training) 0.0174, current loss (val) 0.0184
Epoch 316, current loss (training) 0.0184, current loss (val) 0.0189
Epoch 317, current loss (training) 0.0177, current loss (val) 0.0186
Epoch 318, current loss (training) 0.0186, current loss (val) 0.0198
Epoch 319, current loss (training) 0.0183, current loss (val) 0.0197
Epoch 320, current loss (training) 0.0187, current loss (val) 0.0193
Epoch 321, current loss (training) 0.0175, current loss (val) 0.0190
Epoch 322, current loss (training) 0.0185, current loss (val) 0.0194
Epoch 323, current loss (training) 0.0183, current loss (val) 0.0192
Epoch 324, current loss (training) 0.0175, current loss (val) 0.0185
Epoch 325, current loss (training) 0.0176, current loss (val) 0.0185
Epoch 326, current loss (training) 0.0173, current loss (val) 0.0184
Epoch 327, current loss (training) 0.0180, current loss (val) 0.0189
Epoch 328, current loss (training) 0.0170, current loss (val) 0.0184
Epoch 329, current loss (training) 0.0183, current loss (val) 0.0187
Epoch 330, current loss (training) 0.0177, current loss (val) 0.0185
Epoch 331, current loss (training) 0.0168, current loss (val) 0.0186
Epoch 332, current loss (training) 0.0182, current loss (val) 0.0188
Epoch 333, current loss (training) 0.0171, current loss (val) 0.0185
Epoch 334, current loss (training) 0.0173, current loss (val) 0.0186
Epoch 335, current loss (training) 0.0176, current loss (val) 0.0183
Epoch 336, current loss (training) 0.0176, current loss (val) 0.0185
Epoch 337, current loss (training) 0.0176, current loss (val) 0.0184
Epoch 338, current loss (training) 0.0182, current loss (val) 0.0188
Epoch 339, current loss (training) 0.0170, current loss (val) 0.0183
Epoch 340, current loss (training) 0.0177, current loss (val) 0.0183
Epoch 341, current loss (training) 0.0184, current loss (val) 0.0193
Epoch 342, current loss (training) 0.0184, current loss (val) 0.0192
Epoch 343, current loss (training) 0.0176, current loss (val) 0.0183
Epoch 344, current loss (training) 0.0181, current loss (val) 0.0186
Epoch 345, current loss (training) 0.0179, current loss (val) 0.0187
Epoch 346, current loss (training) 0.0183, current loss (val) 0.0196
Epoch 347, current loss (training) 0.0172, current loss (val) 0.0182
Epoch 348, current loss (training) 0.0179, current loss (val) 0.0187
Epoch 349, current loss (training) 0.0172, current loss (val) 0.0187
Epoch 350, current loss (training) 0.0175, current loss (val) 0.0187
Epoch 351, current loss (training) 0.0175, current loss (val) 0.0185
Epoch 352, current loss (training) 0.0174, current loss (val) 0.0186
Epoch 353, current loss (training) 0.0184, current loss (val) 0.0190
Epoch 354, current loss (training) 0.0176, current loss (val) 0.0186
Epoch 355, current loss (training) 0.0177, current loss (val) 0.0188
Epoch 356, current loss (training) 0.0183, current loss (val) 0.0189
Epoch 357, current loss (training) 0.0171, current loss (val) 0.0185
Epoch 358, current loss (training) 0.0178, current loss (val) 0.0191
Epoch 359, current loss (training) 0.0179, current loss (val) 0.0188
Epoch 360, current loss (training) 0.0175, current loss (val) 0.0186
Epoch 361, current loss (training) 0.0176, current loss (val) 0.0186
Epoch 362, current loss (training) 0.0174, current loss (val) 0.0185
Epoch 363, current loss (training) 0.0172, current loss (val) 0.0184
Epoch 364, current loss (training) 0.0176, current loss (val) 0.0185
Epoch 365, current loss (training) 0.0170, current loss (val) 0.0184
Epoch 366, current loss (training) 0.0176, current loss (val) 0.0184
Epoch 367, current loss (training) 0.0181, current loss (val) 0.0189
Epoch 368, current loss (training) 0.0187, current loss (val) 0.0197
Epoch 369, current loss (training) 0.0179, current loss (val) 0.0185
Epoch 370, current loss (training) 0.0182, current loss (val) 0.0190
Epoch 371, current loss (training) 0.0170, current loss (val) 0.0186
Epoch 372, current loss (training) 0.0175, current loss (val) 0.0186
Epoch 373, current loss (training) 0.0178, current loss (val) 0.0183
Epoch 374, current loss (training) 0.0175, current loss (val) 0.0189
Epoch 375, current loss (training) 0.0191, current loss (val) 0.0201
Epoch 376, current loss (training) 0.0181, current loss (val) 0.0191
Epoch 377, current loss (training) 0.0168, current loss (val) 0.0184
Epoch 378, current loss (training) 0.0185, current loss (val) 0.0194
Epoch 379, current loss (training) 0.0174, current loss (val) 0.0184
Epoch 380, current loss (training) 0.0183, current loss (val) 0.0188
Epoch 381, current loss (training) 0.0177, current loss (val) 0.0190
Epoch 382, current loss (training) 0.0179, current loss (val) 0.0185
Epoch 383, current loss (training) 0.0175, current loss (val) 0.0183
Epoch 384, current loss (training) 0.0180, current loss (val) 0.0188
Epoch 385, current loss (training) 0.0177, current loss (val) 0.0187
Epoch 386, current loss (training) 0.0178, current loss (val) 0.0188
Epoch 387, current loss (training) 0.0176, current loss (val) 0.0192
Epoch 388, current loss (training) 0.0175, current loss (val) 0.0189
Epoch 389, current loss (training) 0.0181, current loss (val) 0.0184
Epoch 390, current loss (training) 0.0175, current loss (val) 0.0187
Epoch 391, current loss (training) 0.0180, current loss (val) 0.0185
Epoch 392, current loss (training) 0.0180, current loss (val) 0.0187
Epoch 393, current loss (training) 0.0172, current loss (val) 0.0187
Epoch 394, current loss (training) 0.0175, current loss (val) 0.0184
Epoch 395, current loss (training) 0.0185, current loss (val) 0.0196
Epoch 396, current loss (training) 0.0180, current loss (val) 0.0187
Epoch 397, current loss (training) 0.0173, current loss (val) 0.0185
Epoch 398, current loss (training) 0.0178, current loss (val) 0.0185
Epoch 399, current loss (training) 0.0172, current loss (val) 0.0184
Epoch 400, current loss (training) 0.0176, current loss (val) 0.0185
Epoch 401, current loss (training) 0.0176, current loss (val) 0.0187
Epoch 402, current loss (training) 0.0174, current loss (val) 0.0184
Epoch 403, current loss (training) 0.0191, current loss (val) 0.0192
Epoch 404, current loss (training) 0.0207, current loss (val) 0.0202
Epoch 405, current loss (training) 0.0170, current loss (val) 0.0185
Epoch 406, current loss (training) 0.0176, current loss (val) 0.0186
Epoch 407, current loss (training) 0.0178, current loss (val) 0.0184
Epoch 408, current loss (training) 0.0176, current loss (val) 0.0188
Epoch 409, current loss (training) 0.0166, current loss (val) 0.0183
Epoch 410, current loss (training) 0.0178, current loss (val) 0.0186
Epoch 411, current loss (training) 0.0175, current loss (val) 0.0188
Epoch 412, current loss (training) 0.0184, current loss (val) 0.0192
Epoch 413, current loss (training) 0.0177, current loss (val) 0.0186
Epoch 414, current loss (training) 0.0175, current loss (val) 0.0185
Epoch 415, current loss (training) 0.0176, current loss (val) 0.0187
Epoch 416, current loss (training) 0.0175, current loss (val) 0.0189
Epoch 417, current loss (training) 0.0176, current loss (val) 0.0188
Epoch 418, current loss (training) 0.0175, current loss (val) 0.0185
Epoch 419, current loss (training) 0.0172, current loss (val) 0.0186
Epoch 420, current loss (training) 0.0179, current loss (val) 0.0191
Epoch 421, current loss (training) 0.0171, current loss (val) 0.0182
Epoch 422, current loss (training) 0.0182, current loss (val) 0.0186
Epoch 423, current loss (training) 0.0175, current loss (val) 0.0188
Epoch 424, current loss (training) 0.0188, current loss (val) 0.0192
Epoch 425, current loss (training) 0.0184, current loss (val) 0.0187
Epoch 426, current loss (training) 0.0177, current loss (val) 0.0186
Epoch 427, current loss (training) 0.0174, current loss (val) 0.0186
Epoch 428, current loss (training) 0.0174, current loss (val) 0.0189
Epoch 429, current loss (training) 0.0209, current loss (val) 0.0217
Epoch 430, current loss (training) 0.0175, current loss (val) 0.0185
Epoch 431, current loss (training) 0.0181, current loss (val) 0.0185
Epoch 432, current loss (training) 0.0173, current loss (val) 0.0188
Epoch 433, current loss (training) 0.0171, current loss (val) 0.0183
Epoch 434, current loss (training) 0.0181, current loss (val) 0.0188
Epoch 435, current loss (training) 0.0180, current loss (val) 0.0184
Epoch 436, current loss (training) 0.0196, current loss (val) 0.0204
Epoch 437, current loss (training) 0.0194, current loss (val) 0.0202
Epoch 438, current loss (training) 0.0182, current loss (val) 0.0189
Epoch 439, current loss (training) 0.0192, current loss (val) 0.0193
Epoch 440, current loss (training) 0.0174, current loss (val) 0.0187
Epoch 441, current loss (training) 0.0182, current loss (val) 0.0188
Epoch 442, current loss (training) 0.0175, current loss (val) 0.0185
Epoch 443, current loss (training) 0.0180, current loss (val) 0.0186
Epoch 444, current loss (training) 0.0174, current loss (val) 0.0188
Epoch 445, current loss (training) 0.0182, current loss (val) 0.0187
Epoch 446, current loss (training) 0.0175, current loss (val) 0.0188
Epoch 447, current loss (training) 0.0186, current loss (val) 0.0186
Epoch 448, current loss (training) 0.0171, current loss (val) 0.0184
Epoch 449, current loss (training) 0.0175, current loss (val) 0.0185
Epoch 450, current loss (training) 0.0174, current loss (val) 0.0187
Epoch 451, current loss (training) 0.0177, current loss (val) 0.0184
Epoch 452, current loss (training) 0.0179, current loss (val) 0.0184
Epoch 453, current loss (training) 0.0172, current loss (val) 0.0184
Epoch 454, current loss (training) 0.0169, current loss (val) 0.0183
Epoch 455, current loss (training) 0.0180, current loss (val) 0.0189
Epoch 456, current loss (training) 0.0175, current loss (val) 0.0186
Epoch 457, current loss (training) 0.0171, current loss (val) 0.0185
Epoch 458, current loss (training) 0.0174, current loss (val) 0.0186
Epoch 459, current loss (training) 0.0178, current loss (val) 0.0183
Epoch 460, current loss (training) 0.0178, current loss (val) 0.0189
Epoch 461, current loss (training) 0.0177, current loss (val) 0.0190
Epoch 462, current loss (training) 0.0177, current loss (val) 0.0189
Epoch 463, current loss (training) 0.0181, current loss (val) 0.0188
Epoch 464, current loss (training) 0.0173, current loss (val) 0.0187
Epoch 465, current loss (training) 0.0174, current loss (val) 0.0188
Epoch 466, current loss (training) 0.0180, current loss (val) 0.0187
Epoch 467, current loss (training) 0.0175, current loss (val) 0.0187
Epoch 468, current loss (training) 0.0168, current loss (val) 0.0183
Epoch 469, current loss (training) 0.0179, current loss (val) 0.0186
Epoch 470, current loss (training) 0.0176, current loss (val) 0.0185
Epoch 471, current loss (training) 0.0179, current loss (val) 0.0191
Epoch 472, current loss (training) 0.0173, current loss (val) 0.0182
Epoch 473, current loss (training) 0.0172, current loss (val) 0.0187
Epoch 474, current loss (training) 0.0173, current loss (val) 0.0183
Epoch 475, current loss (training) 0.0178, current loss (val) 0.0186
Epoch 476, current loss (training) 0.0185, current loss (val) 0.0189
Epoch 477, current loss (training) 0.0176, current loss (val) 0.0190
Epoch 478, current loss (training) 0.0170, current loss (val) 0.0183
Epoch 479, current loss (training) 0.0173, current loss (val) 0.0184
Epoch 480, current loss (training) 0.0178, current loss (val) 0.0184
Epoch 481, current loss (training) 0.0173, current loss (val) 0.0185
Epoch 482, current loss (training) 0.0177, current loss (val) 0.0185
Epoch 483, current loss (training) 0.0177, current loss (val) 0.0188
Epoch 484, current loss (training) 0.0186, current loss (val) 0.0194
Epoch 485, current loss (training) 0.0172, current loss (val) 0.0187
Epoch 486, current loss (training) 0.0183, current loss (val) 0.0191
Epoch 487, current loss (training) 0.0179, current loss (val) 0.0183
Epoch 488, current loss (training) 0.0179, current loss (val) 0.0187
Epoch 489, current loss (training) 0.0178, current loss (val) 0.0188
Epoch 490, current loss (training) 0.0186, current loss (val) 0.0189
Epoch 491, current loss (training) 0.0175, current loss (val) 0.0185
Epoch 492, current loss (training) 0.0196, current loss (val) 0.0201
Epoch 493, current loss (training) 0.0173, current loss (val) 0.0185
Epoch 494, current loss (training) 0.0176, current loss (val) 0.0186
Epoch 495, current loss (training) 0.0175, current loss (val) 0.0186
Epoch 496, current loss (training) 0.0173, current loss (val) 0.0184
Epoch 497, current loss (training) 0.0175, current loss (val) 0.0184
Epoch 498, current loss (training) 0.0179, current loss (val) 0.0190
Epoch 499, current loss (training) 0.0192, current loss (val) 0.0199
Epoch 500, current loss (training) 0.0171, current loss (val) 0.0184
run_time_first_training_cycle:  4633.61 

Epochs 500, batch size, 200
Nbr training obs 1000000, nbr parameters 25352, obs/parameters 39.44

Starting abc-rs
Percentage done:  2.00 %
Percentage done:  4.00 %
Percentage done:  6.00 %
Percentage done:  8.00 %
Percentage done:  10.00 %
Percentage done:  12.00 %
Percentage done:  14.00 %
Percentage done:  16.00 %
Percentage done:  18.00 %
Percentage done:  20.00 %
Percentage done:  22.00 %
Percentage done:  24.00 %
Percentage done:  26.00 %
Percentage done:  28.00 %
Percentage done:  30.00 %
Percentage done:  32.00 %
Percentage done:  34.00 %
Percentage done:  36.00 %
Percentage done:  38.00 %
Percentage done:  40.00 %
Percentage done:  42.00 %
Percentage done:  44.00 %
Percentage done:  46.00 %
Percentage done:  48.00 %
Percentage done:  50.00 %
Percentage done:  52.00 %
Percentage done:  54.00 %
Percentage done:  56.00 %
Percentage done:  58.00 %
Percentage done:  60.00 %
Percentage done:  62.00 %
Percentage done:  64.00 %
Percentage done:  66.00 %
Percentage done:  68.00 %
Percentage done:  70.00 %
Percentage done:  72.00 %
Percentage done:  74.00 %
Percentage done:  76.00 %
Percentage done:  78.00 %
Percentage done:  80.00 %
Percentage done:  82.00 %
Percentage done:  84.00 %
Percentage done:  86.00 %
Percentage done:  88.00 %
Percentage done:  90.00 %
Percentage done:  92.00 %
Percentage done:  94.00 %
Percentage done:  96.00 %
Percentage done:  98.00 %
Percentage done:  100.00 %
Ending abc-rs
 70.971273 seconds (14.87 M allocations: 2.001 GiB, 0.65% gc time)
end script
